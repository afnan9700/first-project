# first backend project log
## intro
### 27/8/25
Hello everyone! This is a "project" i have been working on from the past few months. I have been very inconsistent and irregular with all of it, which is the reason why the progress has been so slow. i have very heavily relied on chatgpt throughout the project, almost everything was generated by it. and tbh, i dont plan on stopping, because it feels like its working for me well. 

and this log thing was just my personal notes about everything i learned in the process of making the application. i didnt really initially plan on posting it on github. yeah, i obviously expect no one to read it, and the writing in many of the parts is awful. but as i had put in some effort writing it, i figured why not. it could take like an 100kb of github's storage at max, which i hope my pointlesss ramblings can afford.

if you still for some reason, decide to read it, i suggest also having the respective file open. it will make much more sense. 

about the application itself... i have some big plans with how everything i want to add (probably a little overambitious for someone whos never made anything before at all). but considering the point at which it currently is, i just want it to be a very simple and functioning blog app. thats it.

the project is 4 chapters in at the time of writing this. the 5th chapter will start soon. i need to start working on the frontend of the post pages, comment cards, board pages etc. i also need to write about how pagination works in this application. i did implement it, but procrastinated the log. and tbh, even i have forgotten a little about of all it, so i will have to review and then write. i may also have to add pagination to how the board returns its posts. currently, it returns every single post in the board all at once.

aight 

## chapter 1
We first organize the codebase into separate folders, each folder contains files which perform a specific kind of task.
```
/project-root
│
├── /backend
│   ├── /controllers       # Functions that run for each route
│   ├── /models            # Mongoose schemas
│   ├── /routes            # Route definitions
│   ├── /middlewares       # Auth, error handlers, validators
│   ├── /utils             # Helper functions
│   ├── /config            # Database config, JWT secret, dotenv setup
│   ├── /services          # Business logic (e.g., recommendations)
│   ├── server.js          # Entry point for Express app
│   └── .env  
```
Now we set up some of the basic things such as the scripts in package.json, environment variables, installing necessary modules and dev dependencies like nodemon.

The `server.js` is the file where we create the [express](express-js) app object in, attach routes and middlewares to it and listen for requests.
There are also a few other things we do such as loading the environment variables and applying CORS.
- The `require("dotenv").config();` line is related to the [dotenv](dotenv) module, and all it does is to load the values of the variables you defined in .env file into `process.env`, so that you can now reference any variable like `process.env.PORT`.
- [CORS](cors) is implemented by attaching a middleware at the start. The function `cors()` returns a middleware according to the options object you pass as the parameter. You may include the list of allowed origins in the options. I believe by default, only the same origin requests are allowed.
- `app.use(express.json())`. The `express.json()` function returns a middleware that is useful for handling json responses. I don't know what would happen the otherwise but, using that middleware will parse the json string in the request and store in `req.body` (if the `Content-Type` was json).

We now define a collection to store the list of users in. `userModel.js` contains the [mongoose](mongoose) schema object, and exports the model object. We store two variables for each User: username and password.
I decided to not store email because I thought that it would make sense to store email when you are doing some kind of OTP verification thing, or if you are using OIDC or something.

The `authController.js` file contains the route handlers related to authentication. We use bycrypt for password encryption, and [JWT](jwt) for session management.
We define two functions: `register()` and `login()` here.
- **`register()`**
  Since this is a route handler, it takes two parameters: `req` and `res`. `req.body` contains the data sent by the user. We load the data into variables `username` and `password`. We check if the user already exists, encrypt the password and store the username and password in the Users collection in the database. We also generate a JWT and send it as a response.
- **`login()`**
  Check if the username is valid, compare passwords (using bycrypt), send a JWT as response if the password is correct, otherwise an error.

Also, we store the secret key JWT uses as an environment variable `JWT_SECRET` in .env.

## chapter 2
I am here after a looong time (procrastination only after a single day huh). And its been so long that (2 months to be exact) my own codebase has started to look foreign to me. Its so shameful but... Whatever.
So I decided to go over all the files, functions and objects that I have created so far. I don't know if this is a good use of time, but I am going to do it anyway. Yeah I am going to go over each file one by one, and try to explain what it contains in brief. 
I highly suggest you have the files opened and you read them as you read through this explanation, cuz I have explained everything under the assumption that you are seeing the code.

### backend
Starting off with the backend part first. 
I implemented the following routes
- a register route to create a new user (post req to ../register/)
- a login route to get a jwt and be authorized (post req to ../login/)
- a logout route to clear the jwts (post req to ../logout/)
- a create post route (post req to ../posts/)
- get posts by a specific user (get req to ../posts/ with a query parameter)
- get a specific post by its id (get req to ../posts/:postId using route parameters

dont bother reading them. i just put them there to let you know the progress, thats it. i am going to go into everything in more detail.
#### server.js
This is the central file of our whole backend application. We import all routes, add necessary middlewares, and invoke the `server.listen()` function here.

We first load the environment variables, the port numbers and mongodb uri specifically. `require("dotenv").config()` loads all the variables in the .env file into the `process.env` object. Then you can load any specific environment variable by `process.env.<environment_var_name>`.

I am not sure what the app object returned by `express()` by itself. But just think of it as core object of the application which has all of the important methods that involve attaching middlewares, adding new routes, etc. to our backend application.

see [[cors]] first.
The `cors()` function returns a middleware which either accepts or rejects the requests based on the origin. We attach the middleware returned at the start of our application. The whitelist array contains names of origins our server accepts the requests from. Normally, browsers don't attach cookies to the requests which are made to a server. The `credentials: true` value makes the middleware tell the browser to attach cookies to the requests sent. This is important for us, since we are using JWT for authentication and the JWTs are stored as cookies on the client-side.

`express.json()` returns a middleware which automatically parses any json contained within a request. This allows you to do things like `const { username, password } = req.body` (we will do similar stuff a lot later).
`cookieParser()` returns a middleware which allows you parse cookies (yeah). This lets you do stuff like `const token = req.cookies.token`. 

Now we attach all of the routers which we have created in the routes folder to specific routes.

And finally, we call the `server.listen()` function to start the server.
Or we don't. Since we are using MongoDB Atlas (which is a cloud database), we have to first establish a connection with MongoDB Atlas, and only then we can start the server. It is done asynchronously (because requests over the internet are slow) by calling the `mongoose.connect(process.env.MONGO_URI)` function. And if the connection is successful, we call `server.listen()`, else we display the error.

The specifics of what these functions do are (sadly) not relevant to us, who want to only use them and build our website. So if web dev is starting to feel like just calling a bunch of these black box functions, I think that's how its meant to be unfortunately. So that's how the theme of all of this will be going further. But hey, its still complex and hard even after so much abstraction.

Anyway, moving forward, I am going to even more brief from now on since we have got a lot to cover but not so much time.

#### models/
see [[mongoose]]
This file (and any other similar model files) will only contain the definition of the model's schema, and export it as a model. We later import the model, and create specific entries such as `const newUser = new User({ username, password: hashedPassword })`, and save them to the database by calling `await newUser.save()`.

The user model contains a username and a password. I decided to not store email since we wont be implementing any sort of email verification or OIDC.

I have also created the post model, but its pretty self-explanatory.
The `author: { type: mongoose.Schema.Types.ObjectId, ref: "User", required: true }` line means that it stores a User model's reference.

#### controllers/authController.js
Any files inside the controllers folder contain handler functions which routers use.
Just to recall, these handler functions are passed to functions like `post()`, `get()` etc. They are attached to routes, and they are callback functions which take `req` and `res` objects as parameters. Where req is the request received, and res is what the server sends.

authController.js contains three handlers: register, login, logout.

`register()` is an async function because it interacts with the mongodb server.
We first load the username and password from the req into variables.
If any field was not provided, or the username already exists we send a 400 response.
Passwords obviously shouldn't be stored as they are and they need to be hashed before storage. We use bycrypt to hash password. Not sure what salt rounds are.
A new user object is created using the User model from userModel.js. The username and the hashed password are stored in this object. And the object is saved to the database.
The new user has been created. Though it is not required, we also generate a JWT for the user, and include it in the response so that the user wont have to login separately again.

The payload of the JWT contains the user's `_id`, and the JWT secret key is loaded from the .env file. The token is created by the `jwt.sign()` function, and we also pass the expiration time as a parameter.

The token has been created, and it needs to be attached to the response as a cookie now, so that the browser will know to store it as a cookie. This is done using the `res.cookie("token", token, <options object>)` function. I am not sure what the `secure: process.env.NODE_ENV === "production"` value in the options object means. HttpOnly makes the cookie more secure (prevents them from "XSS attacks" but dk what they mean). Others are mostly self-explanatory.

Finally we send a 500 response with a successful login message.

`login()` is also an async function similar to register().
Its mostly similar in terms of cookies and jwt handling. We first check if the username is valid, then we compare the password with the one in the database using `bycrypt.compare()`. If the passwords match, we generate the jwt, send it as a cookie, and send a 500 response.

`logout()` contains only one function call, `res.clearCookie("token", <options_object>)`. I am completely clueless about what the options here are. I mean, I get that the options specified when sending a cookie tell the browser about how the cookie should be stored. But options when clearing a cookie too? look into this later.

#### middleware/authMiddleware.js
Once a user has logged in, the JWT is attached as a cookie to every subsequent request. The purpose of this JWT is to verify that it is really the user who is making the request. See [[jwt]] for more info
Since this verification needs to be done after receiving any request, we store the verification function in a middleware, so that it can be simply be attached to a route when needed.

`requireAuth()` is the middleware function which performs this verification.
We first load the JWT from the cookie into a variable. Then we check if the user is even authenticated (logged in) or not. 
For the verification, we call `const decoded = jwt.verify(token, process.env.JWT_SECRET)`. If the token is valid, the decoded payload is returned. And we attach this decoded payload to the request (by `req.user = decoded`) and forward it to further routes. 
I am not sure why this is done, but yeah, we do use `req.user` later. I mean, couldn't you have just included req.user in the request at the start.
#### routes/authRoute.js
Express provides an object called "Router" (returned by `express.Router()`) which can be used to sort of pack multiple routes and middleware into a single router object. 

Here, the auth router contains all routes and middleware related to auth. A route is created by attaching the handler function, an optional middleware to a route like "/login". The following are the routes we create using the controllers and middleware we have created so far.
- `post("/register", register)`
- `post("/login", login)`
- `post("/logout", requireAuth, logout)`. Also attaching the auth middleware here, because the user should first be logged in to log out.
- We also create an additional route "/me" for testing purposes. It says whether the user is authenticated or not.

That's all of the stuff related to auth backend done and implemented. I also created some stuff related to posts. But its mostly similar what we have done so far, so I am going to be even briefer.

#### controllers/postController.js
I wanted to add three functionalities and these are implemented by the following three handler functions: `createPost()`, `getPostById()`, `getPosts()`.

Before creating the handlers, we also need a model for the posts. This model is in the `models/postModel.js` file. And our post's schema contains `author`, `title`, `content`, and `createdAt`. `author` stores a reference to User who creates the post.

`createPost()`:
The usual, loading the stuff from `req.body` into variables. The request will contain title and content of the Post. We create a new Post object, fill all the details, and save it to the database. That's it.
The `author` value in Post is filled by \_id of the user who is currently logged in and is creating the post. We acquire \_id using `req.user.userId`. Remember that `requireAuth()` middleware attached the decoded payload to the request. And the decoded payload contained user, which we now use to get `user.userId`.
I am not sure why, but at the end we send the value returned by `await newPost.save()` as a response along with the status 500. 

`getPostById()`:
Post Id is passed as a route parameter, so we access it using `req.params`.
We then do this: `const post = await Post.findById(postId).populate("author", "username")`
I am guessing that `findById(postId)` fetches the post which has the specified Id and returns it. `author` field in a Post object only contains the referenced User's Id, and not the user object. `populate("author", "username")` fills the `author` field with the referenced User's username instead of only Id.
The fetched post is then sent as a response.

`getPosts()`:
This function fetches all posts which are on the database. If an optional parameter `author` is passed as a query parameter, we fetch only those posts which have been made by `author`.
Since `author` is passed as a query parameter, it is accessed using `req.query`.
Mongoose's `find()` function takes something called a filter object as a parameter. For ex. `find({author:"xyz"})` will return all posts made by author who has the id "xyz".
So we create a filter object, if the author parameter was passed, we add `author` to the filter. We then just call the find function, sort the posts according to created date, and populate their author fields. All of that is returned along with a status 500.

#### routes/postRoute.js
Like previously, all of the handler functions are attached to routes here.
- `get("/", getPosts)` to get all posts or include an optional query parameter for author.
- `get("/:postId", getPostById)` to get a post by Id. `:postId` is the route parameter.
- `post("/", requireAuth, createPost)` to create a post. Only authenticated users can create posts.

The router object is attached to the main app in server.js.

And that's everything I have created so far on the backend side. There are still so many things to add. A feed, comments, votes, following, tags etc. Its going to be hard I feel.
Anyway, I will explain the frontend stuff now. Honestly, my understanding about frontend isn't as good as backend. But still, I will try. I used react and something called shadcn to build all of it. I created the fronted only for login and register pages though, so not a lot.

### frontend
I decided to use React, and a component library called Shadcn (which utilizes tailwind) for the frontend.
First setup React and tailwind css using Vite (see [[frontend-stuff-js]] if you dk what they are). And follow the steps mentioned on Shadcn's website to setup shadcn. Also the frontend of our application uses typescript instead of javascript. I made the decision because Shadcn mentioned that I should pick "React + Typescript" specifically during the Vite setup. Seems that its ok to have your frontend in typescript and backend in javascript. 

Alright. So there are a ton of files in the directory after setting up everything. I don't know much, but I believe we are mainly concerned with only the "src" folder. There are many files and folders inside src, and I will go over each of them.

`main.tsx` is the core file of the react app. It contains code for mounting the react app to the DOM.
Our main concern with this file is what's inside `<React.StrictMode>`. Typically, after initialization, it contains `<App/>`. `App.tsx` is another file inside the src folder that might export the `<App/>` object. And initially, App.tsx contains a button and a sort of welcome screen. 
So basically, `<React.StrictMode>` contains what that needs to be displayed. You can further use the `<Routes>` tag to define which page gets displayed when. 
For better organization, you may store all routes (created using `<Route>`) in a separate folder called "routes", add the `<Routes>` tag and define routes in `App.tsx` and have `main.tsx` contain only `<App/>`. But for now, we are going to write the routes directly in `main.tsx`.

The `pages/` directory will contain page components. A page component is just what we want in a single web page. We store each page in its own file (such as `LoginPage.tsx`). These page components can be mapped to routes using a `<Route>` tag. 

Reusable components such as buttons, forms, cards etc. are stored in the `components/` folder, `components/ui` more specifically. When you install a new component from shadcn, it appears here.

`assets/` is used to store static files such as images of logos, fonts, icons etc.

`libs/` contains helper functions and other misc stuff which might be used. I believe this is also something which would be handled by Shadcn itself.

I think the remaining files such as `index.css` and `vite-env.d.ts ` are not relevant to us.

Ok I think that should clear up most of the doubts, so I am going to proceed with making the first frontend page of our app now. Again, I will remind it to you once again that all of it was generated by chatgpt, and since my understanding of frontend is much more lacking than backend, so the explanation may not be as good. 

#### pages/RegisterPage.tsx
The function `RegisterPage()` is the main component of the RegisterPage. Again, to recall, a react component is just a function which returns jsx. So that's what `RegisterPage()` is.

Inside the component, we first set up states (using `useState`) for the stuff which will react re-render when it changes - username, password, message. (for useState, see [[frontend-stuff-js]]).

Now we write the event handler function `handleSubmit()` for when the user hits submit.
This function takes `e: React.FormEvent` as a parameter. I don't know much about why this is done, but I think: `e` is just an object which is passed to handler functions by react. And the main reason we use it in the function is to call `e.preventDefault()`. Seems that these "e objects" have a predefined default behavior which gets executed whenever the handler function is called. But we don't want that default behavior to get executed here, so we call `e.preventDefault()` which prevents it.

After the submit button has been clicked, we want the entered data to be sent to our backend, to `auth/register` specifically. So we now use fetch to make a post request to that address, and receive the response. (see [[fetch-api]])
Based on the response, we modify the states. 

Finally, we return the jsx.
Ok, so this is the part I am the most clueless about. But I will still try to make out something. 
- In the main form element, we set the `handleSubmit()` handler for `onClick`. 
  `<form onSubmit={handleSubmit} className="space-y-4">`
- In the input element, we call the state modifying function for `onChange`.
  `<Input ... onChange={(e) => setUsername(e.target.value)} .../>`
- `{message && (<div className="text-sm text-center text-red-500 mt-2">{message}</div>)}`
  It prints nothing if the message is empty, or applies the css and prints the message.

And thats it ig.
The login page (`pages/LoginPage.tsx`) is the same honestly. So I wont explain it again.

I am going to finally start adding new features now.
Also, yeah, I think writing all of this did give me a better understanding of this project. Or at least that's how I feel. Or may be its just something I am saying to cope with all the time I mightve wasted writing this.
Anyway, I will be back tomorrow now. 

## chapter 3
I added many new features in the backend, and a ton of changes. Stuff like comments, votes, boards, etc.
But I was away again for quite a while. So... Kinda lost track of all of it. But no problem, I am going to write a quick review and start working on it again. It is a lot, but nothing is structurally new (in regard to code). So, it will be very brief. I will go over the models, controllers and functions and finally the routes, that's it. 

### backend
#### votes
The first feature I added was votes. Posts can now be upvoted or downvoted.

**`postModel.js`**
Added `votes` field. `votes` is an array that stores `{user,value}` objects. Each user can vote any post only once. And the only way to keep a track of whether a user has made a vote or not is by storing it somewhere. So I decided to store it within the Post model itself. I also added a `voteCount` filed to quickly display the number of votes without recomputation.

There are other design choices too. For example, I could have instead used an array storing `{postId,value}` in the User model, and also have a `voteCount` field in the Post model (for quick vote count access). 

I couldn't think of any reasons why one design could be better than the other. If we consider the length of the array as our limiting factor, then the choice for the better design depends on whether a post receives lesser number of votes (for `Post.votes`), or a user makes votes to lesser number of posts (for `User.votes`). And I felt that a post is more likely to receive lesser number votes, so I went with the `Post.votes` model. 
There is also another subtle issue with using the `User.votes` design (mentioned by gpt). After a user votes, it is possible that due to some error, the value in `User.votes` gets updated, but doesn't in `Post.voteCount` (or the vice versa). Seems that updating two collections (or even documents) instead of one can make inconsistencies more likely (dk why). Though, I think we could add some rollback-like exception handling to handle it.

I also set the `value` in `{user,value}` to be an `enum: [-1,1]` for additional safety.

So basically, just added a votes array and a voteCount field to the Post model to allow voting.

**`postController.js`**. Added `voteOnPost()` handler.

and `router.post("/:postId/vote", requireAuth, voteOnPost)`
#### comments
**`commentModel.js`**
I initially considered embedding comments directly within the Post model, but very quickly realized that it was terrible idea. Comments and replies grow unboundedly, so they need to be stored in a separate collection. Deciding how to structure replies felt a bit challenging. I considered making a different model for replies, but comments and replies felt too similar to in structure to have whole different models, so ended up adding a sort of flag field which indicates whether a comment is a main comment or a reply.

So the `Comment` model now contains
- The basic stuff like author, date created, votes (similar to posts) etc.
- `post` which contains id of the post to which the comment's been made.
- `parentComment` contains id of the comment to which the current comment's is a reply. If `parentComment` is null, the comment is a main comment.

**controllers and routes**
- `router.post('/posts/:postId/comments', requireAuth, createComment)`
  Straightforward. Just see the code.
- `router.get('/posts/:postId/comments', getPostComments)`
- `router.get('/comments/:commentId/replies', getCommentReplies)`
- `router.post('/comments/:commentId/vote', requireAuth, voteOnComment)`
All are self-explanatory. 

#### boards
Boards are like subreddits. Users can join boards, make posts to boards, leave boards. A board also has moderators.

**`boardModel.js`**
name, array of moderators, number of members, array of tags, createdBy.

To map posts and boards, I added a new field `board` to the Post model. It contains the Id of the board to which the post's made. If it is null, then the post is a "user post". Such posts can be viewed in the user's profile.

And to map users and boards, I added `joinedBoards` to User model. 
Actually, I initially added a `members` list to the Board model. But I realized that tracking the members of board could not have many uses, and there is also possibility that the number of members can get big. So I replaced it with `membersCount` instead.
May be I should have implemented moderators similarly too. Having a `moderating` field in the User model instead of `moderators` in the Board model. But a board wont have so many moderators so I let it stay as it was. 

I mentioned that boards can have "tags". These are just strings which have been predefined by the application admins. Tags can be set to a board during the creation, and their purpose is to suggest new boards to users.
The list containing a "allowed tags" is in `utils/allowedTags.js`. Controllers can import the file when its needed.
Users cannot create new tags, and have to use only the ones allowed by the application. This choice was intentional because I felt that custom tags can cause too much clutter.
User model also has a `followedTags` field.

**controllers and routes**
- `router.post('/create', requireAuth, createBoard)`
  Creates a new board and sets the user to be the moderator.
- `router.get('/user/:userId', getUserBoards)`
- `router.post('/:boardId/join', requireAuth, joinBoard)`
- `router.post('/:boardId/leave', requireAuth, leaveBoard)`
- `router.get('/board/:boardId', getPostsByBoard)`

For a few moderator specific routes, I created a `requireModerator` middleware. It just checks if userId is present in board.moderators.

- `router.post('/boards/:boardId/moderators/promote', requireAuth, requireModerator, promoteToModerator)`
- `router.post('/boards/:boardId/moderators/demote-self', requireAuth, requireModerator, demoteSelf);`
- `router.post('/boards/:boardId/kick', requireAuth, requireModerator, kickMember)`
Honestly... All are self-explanatory. Just read the code.

#### deleting and editing
I wanted to now add some routes to delete and edit various things such as posts, comments, boards, profiles etc. 

Deleting would have been simple, just remove the item from the database. But I realized something. What would I do to the replies of a deleted comment, or comments of a deleted post, or posts made by a deleted user etc. So instead of hard deleting an item, I decided that I would "soft delete" them.

What this means is that now, comments, posts, users etc. all have a `deleted` field. After deleting, instead of removing the item from the database, the `deleted` field just gets set to `true`. And any content of the post or comment, username of a user will get set to `[deleted]`. This way, anything that references removed stuff can still be displayed.

Deleted User profiles and Boards require some additional tweaking. The deleted profiles or boards should not show up in the searches, so I added a query middleware (in mongoose) that excludes all records with `deleted: true` from any of the `find` queries.

Using `timestamps: true` in the model definition automatically manages creation and update dates. I used it to keep track of when the post or comment gets deleted.
But I just realized, I think the `updatedAt` managed by `timestamps: true` updates the edit time even if someone votes (because votes are embedded within my Post and Comment models). So I think I might have to create a separate field to track the time when the posts and comments get edited, and set them inside the edit controller. I will do it later.

**routes**
comment related
```
router.patch('/comments/:commentId', requireAuth, editComment);
router.delete('/comments/:commentId', requireAuth, deleteComment);
```
post related
```
router.patch('/posts/:postId', requireAuth, editPost);
router.delete('/post/:postId', requireAuth, deletePost);
```
board related
```
router.patch('/board/:boardId', requireAuth, requireModerator, editBoard);
router.delete("/:boardId", requireAuth, requireModerator, deleteBoard);
```
user related
```
router.delete("/me", requireAuth, deleteUser);
```

**admin stuff**
I also added a way to promote a user to `admin`. Added an `isAdmin` field to the User model.
Running the file `scripts/promoteToAdmin.js` sets the given username to admin. 

There is no route to promote a user to admin. It can be done only by running the script.

added admin routes and controllers, a requireAdmin middleware. its not much, see it yourself.
```
router.delete("/purge", requireAuth, requireAdmin, deleteAllData);
router.get("/stats", requireAuth, requireAdmin, getStats);
```

Aaand... That was everything. 
It was kinda tedious, but hopefully the upcoming things will be interesting. I am going to add a feed for the application now. I am interested about looking into pagination, recommendation algorithms etc. 
But I also need to add a frontend, which is going to be tedious again...

Anyway. That was it for today.

## chapter 4
### frontend
I want to make the frontend now. I also added the feed, but I will talk about it later.
I scraped all of the frontend i initially made using shadcn, and decided to start again using only react (with typescript). i want to keep it as minimal as possible.

first see [[frontend-stuff-js]]

One of my first concerns with the frontend was how we would have display many elements differently based on whether or not the user is logged in. And doing that first requires access to the user's authentication state across all components of the app. And in react, that can be achieved by using contexts.

#### context/authContext.tsx
The main purpose of this context is to give information about the user's authentication status to all components that require it. After the user logs in, our backend sends a jwt to the user, the token is stored as a cookie and is appended to all requests which are further made. So to know whether or not a user is authenticated, you might think that you could just check if the user has a cookie stored. But that is not possible because the cookies we use are http-only. Http-only cookies cannot be accessed using any external javascript (which also includes the js in frontend). They are appended to only those requests which are made to the origin that first issued them (our backend). This is done for security reasons (to prevent xss attacks).

We cant access the cookies directly, but we can communicate with the backend. So we add a new route `/me` to the backend, and the only job of this route is to say whether or not the user is logged in. 

Now we have a way to know about the user's log in status, we make a request to the backend and update the auth context's value based on it. But when exactly should the auth context update it's value? Obviously when the user logs in and logs out. But our tokens can expire, and the user is automatically logged out when that happens, but we don't have a way to know if the cookie has expired. To handle it, we update the value of auth context every time the app is rendered for the first time. Now if the token has expired, the frontend would know it as `/me` is polled after every initial render. Yes, it is possible that the token expires after the application's initial render. When that happens, the frontend would show the user as logged in, but the backend will throw errors. We may handle those error by something like forcing a page refresh (dont know if its possible), and showing a session expiration message. 

So far, I said that we would use the auth context to know about the user's log in status. There's some other information too about the logged in user which is very helpful if its available to all components (things like username, user `_id`). 

Ok now to the actual code.
Since we are using typescript, I will first show what the auth context looks like
```typescript
type AuthContextType = {
  user: User | null;
  loading: boolean;
  login: () => Promise<void>;
  logout: () => Promise<void>;
};
```
login and logout are functions which when called make a request to `/me` and update the value of AuthContext. 

We also have a loading state. The loading gets set to true before making the asynchronous requests (like fetch), and gets set back to false after the response gets received. 

`const [user, setUser] = useState<User | null>(null)`. The main state which will store the username of the logged in user. If the user is not logged in, it gets set to null. Also, the User object stores the `_id` and username. 

There is a certain snippet from the code which can appear confusing because of our inexperience with typescirpt.
```typescript
const AuthContext = createContext<AuthContextType | undefined>(undefined);
export const AuthProvider: React.FC<{ children: React.ReactNode }> = ({ children }) => {  });
```
`createContext` (and many other functions) in react uses generics, and what you pass in those angular braces determines the type of value the context will store (it could mean something else for other functions). 

`React.FC` is the type of all react functional components. And its generic takes the type of any prop which the functional component uses. `AuthContext` is also a functional component (it returns the jsx containing the context's provider). I am not completely sure about `children: React.ReactNode` either, but heres what I think: `React.ReactNode` is the type of anything that react renders ("node" because its a part of the component tree). And the children components are passed as props to other components, and I think thats why `children: React.ReactNode` could be here. But I could be wrong.

Finally we also write a custom "hook" (not sure why we call that), to simplify the context usage even more. Normally, you would have to do something like `const context = useContext(AuthContext)` or something similar to load the context's value in a variable. Instead we wrap all of that in the function `useAuth()`, and now you can directly call this function to load the context value.

And that should explain authContext.tsx.

#### utils/useAsync.ts
Say you want to render the comments of a post. To render the comments, you have to first fetch them from the backend. And the process of making that fetch request is asynchronous. Async function calls inside a component are considered to be "side effects", and they are handled inside the `useEffect()` hook. 

`useEffect()` handles the side effect execution based on the passed dependency array. Since the side effect function is asynchronous and returns a promise, javascript queues the function and proceeds with the execution of other things. While the async function (eg. the fetch request) is under execution, the frontend would have nothing to display. So, instead of displaying nothing, we also use a loading state to provide feedback on the frontend that the request is under execution. The loading state is set to true at the start of the async function's execution, and gets set to false after either the returned promise resolves or returns an error. 

So essentially, the async function could exist in 4 states
- Initial state when it hasn't started it's execution yet.
- Loading state for when its under execution.
- Success.
- Error.
And the frontend should change appropriately based on the async function's state. To track the function state, and trigger re-renders appropriately, we use three state variables: `data`, `loading`, `error`.
- Initial state - `data: null`, `loading: false`, `error: null`.
- Loading state - `data: null`, `loading: true`, `error: null`.
- Success - `data: ?`, `loading: false`, `error: null`.
- Error - `data: null`, `loading: false`, `error: error`.
Whenever any of the three states change, the component which calls `useAsync()` gets re-rendered, displaying the appropriate state of the async function call.

We also maintain a `mounted` flag to avoid setting state on a component that isn't mounted. `useEffect()`'s cleanup function ensures that `mounted` gets correctly set to `false` after the component unmounts.

`useAsync()` also takes an optional dependency array which specifies when `useEffect()` should call the function based on the component's mounted state.

#### utils/fetchWithAuth.ts
It is another utility function that simplifies having to write `credentials: 'include'`, `'Content-Type': 'application/json'`, some error handling by packing all of it into a single function. `fetchWithAuth()` takes the same parameters as `fetch()` (`input`, `init`). 

Not much to say about this. It is an async function, so be sure to call it inside the `useAsync()` hook.

**context/ToastContext.tsx**
Toast messages are hovering messages that appear on the screen to give feedback to the user about various actions. Things such as "Post created successfully", "Comment created" and other similar notifications. These messages usually appear at the bottom or the bottom right of the screen, and automatically fade away after some time. 

So we want to design the toast notification system such that it can be triggered by any component. And that sounds a lot like what contexts do. So maybe, we could share an array of notifications to all components as context, and when any component wants to send a notification, its sent by simply appending it to the context array, and after a set time passes, it also removes it. And the component which renders the toast notifications uses `useContext` to get the array and renders it on the screen. 

But before I proceed with  how we actually implement it, I want you to first understand this snippet from [[frontend-stuff-js]]
>The values provided by contexts shouldn't have to be a variable or an object, contexts can provide functions too. And sometimes, those functions can alter a state, and that state change might trigger a re-render. Do note that, it is actually a function instance that gets passed as the "value". An implication of it is that any states defined in that function are the same across function calls made by the child components of the context. "But why would you do it? Aren't you still essentially just sharing a state across the child components? Why not pass the state directly?". I am not sure, but from how I understand it, the answer is just abstraction. When you are sure that a state is going to be modified in only a very specific way by any component, instead of passing the state and having to re-write that state modification inside every child component, you instead pass the modification itself, and because of how states and functions work, you would be essentially also sharing the state at the same time.

That's exactly what we do in ToastContext too.
Instead of providing the context array, we store the context array as a state inside the function which gets provided by ToastContext. Whenever a child component needs to send a notification, it can simply call the provided function, instead of having to manually edit the toast array.

That's all it does. So elegant. 

Oh and about the uuid...
So we also want the toast which gets added into the array to be removed after 3sec. And to remove an item from an array, you would need a way to identify the item you want to remove. And how would you identify it? Using the index of the element when it was inserted isn't reliable because the index will get changed after a new toast arrives. You might think of updating the indexes of each toast each time after a new toast arrives, but that's too many steps. So to avoid all of the complexity, we just use uuid. A uuid is basically just a random string that gets generated, and its said that the chances of a duplicate uuid ever being generated are astronomically low. So that's why uuid.

But I think we could have used time as an id too. Idk why we chose uuid instead. One unlikely scenario where time could case problems is if two notifications get sent in the same millisecond, but I don't know if it happens commonly enough to worry about. But even that wouldn't really be problematic right? I mean, multiple toasts would get removed instead of one, so that is still the intended behavior. Maybe gpt was hallucinating when it said uuids are better.

## chapter 5
Most of the frontend utilities have been implemented, and I was about to start working on page components like post cards, post pages, board pages and so on, but felt like I should review my backend a little bit first. And I also thought that this would be a good time to talk about the paginated feed I had implemented.
### backend
first see [this](pagination) if you are unfamiliar with pagination

As returning one thousand posts in a single response isn't ideal, we paginate. And I decided to go with cursor-based pagination. Reasons being I understand it better (i dont understand how offset works), and it is also apparently more efficient. 

Before getting into details about the function, I will first say how I envision pagination to work in my app. 

So we want the backend to return only `pageSize` number of pages based on the cursor that has been included in the request. If the feed is sorted according to `sortField`, the pagination function is going to use the the page `n` 's last post's `sortField` to fetch the page `n+1`. For example, if the feed is sorted according to `createdAt`, the posts in the page `n+1` will be older than page `n`'s last post's `createdAt`.

When a user clicks the "next" button to fetch the next page of the feed, the cursor is included in the request. And the backend can use the cursor included in the request to return the next page. 

What if the user has opened the feed for the first time, and does not have the cursor? In that case, the request is sent without the cursor in the query parameters. When no cursor has been included, the backend simply fetches the top `pageSize` posts according to the `sortField` and sends them as the response. Now if the user wants to see the next page, the cursor to include in the parameters is available.

What about previous pages? We could implement navigating to previous page in the exact same way as navigating to the next page. Instead of fetching posts older than the cursor, you would fetch posts newer than the cursor. And you would also have to add a way to distinguish between next page and previous page requests. 

But I decided to do it in a different way. In my application, the contents of each page are extremely lightweight. Each page just consists of simple metadata about posts and nothing else. So I thought that we could just cache the requested pages on the frontend. Caching each page's cursor is an option too, and it would be even more lightweight, but I want to go with caching the whole page. 

I haven't implemented the frontend caching part yet. And honestly, I don't know anything about how I am going to do it yet. But here's what I think I may have to do: For each page received, the frontend would have to keep a track of each page along with it's page number. When a page number which is available in the cache is fetched, we don't make a request to the backend and return the cached page. 

When should the cache be cleared? This is the part I am the most confused about currently. I am guessing it should happen either when a request gets made to `/feed` route without cursor included in the parameters, or... if a request is made to any route other than `/feed`? I thought so, but there is one thing I don't know how my app is going to handle at all. Say you are currently on page 4 of the feed, you click on one of the posts in the feed and it takes you to that post's page, you read the post and want to go back to the feed now, so you click the "go back <-" button in the browser. What happens now? If delete the cache after a request is made to a route which isn't `/feed`, the user can't go back to page 4 anymore. So maybe I can add my custom go back button maybe? I don't know, I need to look into it more seriously, which I will later when I am working with the frontend.

#### utils/paginateQuery.js
Initially, I had implemented the entire pagination within the `getFeed()` controller itself. But I soon realized that the "pagination" pattern is something I am going to use in several other places too (such as in `getPostsByBoard` or `getPostsByUser`). And I don't want to write the everything all over again there. So I decided to separate the pagination logic as a utility function. 

`paginateQuery()` takes things like `filter`, `sortField`, `Model` etc. as parameters. They are required to fetch the a page of items from the specified collection. We also use `_id` of the items as a tie-breaker for when two items have the same `sortedField`. And there isn't really much to say about it. But one thing I would like to mention is how well chatgpt implemented it. Have a look at the parameters it takes
```javascript
async function paginateQuery({
  Model,    // collection/model to query
  filter = {},  
  cursor,   // cursor base-64 string from client
  sortField = 'createdAt',
  sortOrder = -1,
  limit = 10,   // number of items per page
  populate = [],    // fields of the model to populate
  projection = null,    // fields from the model to return
}) {
	// ...
}
```
I didn't even get the idea that to pass populate and projection as parameters, but doing it makes so much sense. 

In my previous implementation, I used the `_id` of the post as the cursor instead of values of specific fields like `createdAt` or `voteCount`. I thought that it was simplistic, but the backend would have to make a database query to get the values of `createdAt` to actually fetch the page contents. That query could be avoided if I had passed the value of `createdAt` directly. So that's what I did when I updated it. Instead of using `_id` as the cursor, we use `base64({_id: id, sortField: sortField})`.  Now, the backend wont have to perform that additional query to get the value of cursor's `sortField`.

Why bother with base64 encoding? Tbh, I did it for the sole reason that it looked better to me and nothing else. Something about exposing information so plainly in the url feels kinda wrong. Yeah yeah yeah, I know, I know, base64 can be decoded in an instant, so its all still practically exposed. Yes, that's why I said that it was an aesthetic choice.  One thing I will mention is this `Buffer.from(JSON.stringify(payload)).toString('base64')`. The reason that `Buffer.from()` function is used because apparently you cannot convert a string (which `JSON.stringify()` returns) to base64 directly. So you have to first convert it to raw binary data using `Buffer.from()`, then you can use `toString('base64')`.

I then used the utility function to implement the `getFeed()` controller. I also added pagination to `getPostsByBoard()` and `getPostsByUser()` controllers. 

And while I was doing all that, I realized some pretty serious problems with all the code I had written.

#### misc. changes
The first problem was simple, but may substantially improve performance. There were many fields in my code which contained only references to other documents. It is usually not a problem and in fact, a good thing because it keeps the data consistent and avoids redundancy too. But, if any of such fields are going to need to be populated often, the a database query is also going to run just as often. And the database query could be avoided if the field was denormalized. 

For example, the `author` and `board` fields in my `Post` model contained only references. So to get the name of the author and board, the backend would have to query the database every time a post needs to displayed. And all of that could have been avoided if I just added additional fields `authorName` and `boardName`. 

The other field I denormalized was `joinedBoards` in the `User` model. This was slightly trickier to implement. As `joinedBoards` is an array, I couldn't just add another array `joinedBoardNames`, I had to change the `joinedBoards` array to instead store values like `{ boardId, boardName }`. 
That was the easy part. The problem occurred in `joinBoard()` and `leaveBoard()` controllers. The two functions use `user.joinedBoards.includes(boardId)` to check if the user is in the board. The problem is, `includes()` checks the memory address of the object which is passed to it and the objects in the array. This wasn't a problem in before the denormalization because `joinedBoards` was an array of strings, and strings are primitives. So instead of `includes()`, I had to use `user.joinedBoards.some(board => board.boardId.equals(boardId))`. 

I denormalized some other fields too, such as `userName`, `postTitle`, etc.

That was the first fix I did. The second was a more serious and a subtler one. 

Many controllers in the application had a behavior similar to
1. `find()` a document from the database.
2. Modify it in some way.
3. `save()` the document back to the database.
And node js executes all of this asynchronously. 

I think you can see where this is going. It's the lost update problem. Lets take the `voteOnPost()` controller as an example, as I feel its the most susceptible to the problem. The user clicks the upvote button two times very quickly, which will trigger two `voteOnPost()` calls. The problem is, before the first `voteOnPost()` call has called `save()`, the second `voteOnPost()` call calls `find()`. And that will cause the second upvote button update to be lost. 

To avoid it, it should be made sure that whole process happens in a single call. So, instead of using `find()`, modify, then `save()`, we use `updateOne()` or `updateMany()` functions provided by mongoose. So I refactored the `voteOnPost()` and `voteOnComment()` functions accordingly. It was interesting how the restriction of strictly only using `updateOne()` or `updateMany()` affected the way the functions had to be written. `updateOne()` and `updateMany()` also take a filter parameter which specifies the documents which that should get updated. We use that filter to specify how the vote value should change based on its current value. 

I should keep the lost updates in mind from now on. I implemented the atomic behavior in only the vote functions and nowhere else though. I didn't feel the necessity anywhere else. I considered implementing it in the `joinBoard` or `leaveBoard` controllers, but decided that I would instead just show "loading" on the frontend to prevent the user from making any other requests until the join or leave operation completes.

And... That was all of what I did. I will start working on the frontend again from tomorrow now. One thing I am feeling a little worried about is that I made ALL those changes to the app in only a single commit. So if anything has gone wrong, I don't have the option to just rollback as the last commit is from a long time ago. Ugh whatever I am not going to think about it. I think it should work because it all seemed to make sense to me as I was writing all of it. But.. Idk. 

ok bye.